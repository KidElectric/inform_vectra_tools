import numpy as np
import pandas as pd
from sklearn.metrics import pairwise_distances
from scipy.spatial import Delaunay

def df_to_cell_type_dict(df,
                        cell_col = 'Phenotype',
                        tissue_col = 'Tissue Category',
                        cell_x_pos = 'Cell X Position',
                        cell_y_pos = 'Cell Y Position',
                        col_dict = None,
                        ):
    #If a dictionary is provided, use that instead
    if col_dict != None:
        cell_col = col_dict['cell_col']
        tissue_col = col_dict['tissue_col']
        cell_x_pos = col_dict['cell_x_pos']
        cell_y_pos = col_dict['cell_y_pos']
        
    points = df.loc[:,
                    (cell_x_pos,
                     cell_y_pos)
                   ].values
    point_types = df.loc[:,cell_col].values
    tiss_types = df.loc[:,tissue_col].values

    #Make dictionary:
    point_lookup={tuple(point):(cell,tissue) \
                  for point,cell,tissue in zip(points,point_types,tiss_types)}
    return point_lookup

def point_to_vert(points, point):
    '''
        point_to_vert(points,point)
        points = n x 2 np.array()
        point = 1 x 2 np.array e.g. [0.123, 23.0] (x,y)
        
        Return: int. index in points == point 
    '''
    idx = np.all(points == point,axis=1)
    if np.sum(idx) == 1:
        out = int(np.argwhere(idx))
    else:
        out = -1
    return out

def vert_to_connected_verts(vert, delaunay):
    '''
    
    Parameters
    ----------
    vert : int
        One vertex of delaunay simplex corresponding to a point.
    delaunay : Delaunay scipy object
        see: scipy.spatial.Delaunay

    Returns
    -------
    all_verts : np.array
        Array of vertices connected to input vertex via one hop.

    '''
    all_simp_with_vert = [i for i,s in enumerate(delaunay.simplices) \
                          if vert in s]
    all_verts = np.array([])
    for simp in all_simp_with_vert:
        verts = delaunay.simplices[simp]
        all_verts = np.concatenate((all_verts,verts))
    all_verts = np.unique(all_verts).astype(int)
    all_verts = all_verts[all_verts != vert]
    return all_verts

def point_list_to_celltype(point_list, point_lookup):
    '''
    
    Parameters
    ----------
    point_list : np.array
         n rows by 2 array with xy coords: [[x,y],]
    point_lookup : dictionary
        tuple([x,y]) is key in dictionary for value generated by
        df_to_cell_type_dict()

    Returns
    -------
    out : list
        List of output values associated with [x,y] keys

    '''
    out = []
    for point in point_list:
        out.append(point_lookup[tuple(point)])
    return out

def cell_dist_criterion(center_xy,
                        neighbor_cell_xy, #point list
                        radius = 50,
                        scale =  1):   
    dist = pairwise_distances(neighbor_cell_xy,
                              center_xy.reshape(1, -1),
                              metric='euclidean').flatten()
    scaled_dist = dist * scale
    is_neighbor = scaled_dist < radius
    return is_neighbor, scaled_dist

def df_to_connections_output(subset,
                             cell_col = 'Phenotype',
                             tissue_col = 'Tissue Category',
                             scale = 1,
                             max_dist = 500,
                             ):
    '''
        Take subset of segmented cell dataframe and calculate connection counts for each cell as a hub.
        Inputs:
           subset - pd.DataFrame of segmented cell coordinates and types
             
    '''
    if subset.shape[0] > 0:
        point_lookup = df_to_cell_type_dict(subset,
                                            cell_col = cell_col,
                                            tissue_col = tissue_col)
        points = subset.loc[:,('Cell X Position',
                               'Cell Y Position')
                               ].values
        tri = Delaunay(points)
        i = 0
        connections = pd.DataFrame()
        print('Beginning cell connection detection...')
        hub_cell_points = subset.loc[:,
                            ('Cell X Position',
                             'Cell Y Position')
                           ].values    

        #For each cell as a hub, count types of connections    
        for i, hub in zip(subset.index,hub_cell_points):
            vert = point_to_vert(tri.points, hub)
            if vert > 0:
                connected_verts = vert_to_connected_verts(vert, tri)
                connected_points = tri.points[connected_verts]

                #Filter out cells > max_dist um away:
                is_neighbor, dists = cell_dist_criterion(tri.points[vert],
                                          connected_points,
                                          radius = max_dist,
                                          scale = scale)
                cx_ids = connected_verts[is_neighbor]
                connected_points = connected_points[is_neighbor]
                connected_dists = dists[is_neighbor]
                spoke_cell_types = point_list_to_celltype(connected_points, point_lookup)
                temp = pd.DataFrame(spoke_cell_types, columns = ['cx_cell','cx_tissue'])
                temp['dist_um'] = connected_dists
                temp['hub_id'] = i
                temp['cx_id'] = cx_ids
                temp['hub_cell'] = subset.loc[i, cell_col]
                temp['hub_tissue'] = subset.loc[i, tissue_col]
                temp['tls_id'] = subset.loc[i,'tls_id']                
                connections = pd.concat((connections,temp),axis=0)
            else:
                print(i,hub,'Not found')
        
    else:
        connections = pd.DataFrame(columns = ['cx_cell',
                                       'cx_tissue',
                                       'dist_um',
                                       'hub_id',
                                       'cx_id',
                                       'hub_cell',
                                       'hub_tissue',
                                       'tls_id'])

    return connections.reset_index(drop=True)

def generate_log_odds_matrix(connections,
                             cell_names,
                             tissue_types,
                             version = 1,
                            ):
    if connections.shape[0] > 0 :                             
        output = np.zeros((len(cell_names),len(cell_names)))
        for i,hub_type in enumerate(cell_names):
            for j,spoke_type in enumerate(cell_names):
                if version == 1:
                    use_hub = connections.loc[:,'hub_cell'].values == hub_type
                else:
                    if any([hub_type == x for x in tissue_types]):
                        use_hub = connections.loc[:,'hub_tissue'] == hub_type
                    else:
                        use_hub = connections.loc[:,'hub_cell'] == hub_type

                if any([spoke_type == x for x in tissue_types]):
                    use_spoke = connections.loc[:,'cx_tissue'] == spoke_type
                else:
                    use_spoke = connections.loc[:,'cx_cell'] == spoke_type
                a = np.sum(use_hub & use_spoke) #Total n connections of hub-type i to spoke-type j.
                na = np.sum(use_hub & ~use_spoke) #Total n connections of hub-type i to Not spoke-type j.
                output[j,i] = a / na
        output = np.log(output+.0001) #there are better corrections
    else:
        output = np.zeros((len(cell_names),len(cell_names))) + np.nan
    return output

